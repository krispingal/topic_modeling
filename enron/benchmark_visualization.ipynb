{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gensim Benchmark Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "sns.set(style=\"white\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "OUT_DIR = \"../../Data/out\"\n",
    "perf_out_file = \"perf_enron.csv\"\n",
    "df_perf = pd.read_csv(os.path.join(OUT_DIR, perf_out_file))\n",
    "time_cols = [col for col in df_perf.columns if 'pass' in col]\n",
    "df_perf['mean_time'] = df_perf[time_cols].mean(axis=1)\n",
    "df_perf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_perf.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "sns.pointplot(x='num_topics', hue=\"implementation\", y='mean_time', data=df_perf, pallete=\"Set2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance\n",
    "\n",
    "Going deeper down the rabbit hole, to see how Gensim's LDA Multicore fares against Mallet's LDA in terms of performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 4))\n",
    "sns.pointplot(x='num_topics', hue=\"iterations\", y='mean_time', data=df_perf[df_perf['implementation'] == 'Gensim'], pallete=\"Set1\", ax=ax1)\n",
    "sns.pointplot(x='num_topics', hue=\"iterations\", y='mean_time', data=df_perf[df_perf['implementation'] == 'Mallet'], pallete=\"Set3\", ax=ax2)\n",
    "plt.suptitle('Num topics vs mean time', fontsize=20)\n",
    "ax1.set_title('Gensim')\n",
    "ax2.set_title('Mallet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 4))\n",
    "sns.pointplot(x='num_topics', hue=\"workers\", y='mean_time', data=df_perf[df_perf['implementation'] == 'Gensim'], pallete=\"Pastel\", ax=ax1)\n",
    "sns.pointplot(x='num_topics', hue=\"workers\", y='mean_time', data=df_perf[df_perf['implementation'] == 'Mallet'], pallete=\"Set3\", ax=ax2)\n",
    "plt.suptitle('Num topics vs mean time', fontsize=20)\n",
    "ax1.set_title('Gensim')\n",
    "ax2.set_title('Mallet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coherence\n",
    "Next we will be looking at the coherences of models we obtain.\n",
    "** Let me just state that this comparison will not be an apples to apples comparison. Both Libraries provide many more parameters over which the model can be tuned with. This study has not exhausted all the individual parameters.**\n",
    "\n",
    "So it is definitely possible that one could end up with a much better model than the ones that are displayed here.\n",
    "\n",
    "Also note that unlike how we timed the LDA call, by averaging out the time over n times, the current code does not measure coherence of models over those n times. This is because computing coherence is an expensive call. So this one will be slightly less accurate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "if 'UMass_coherence' in df_perf.columns :\n",
    "    f, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 4))\n",
    "    sns.pointplot(x='num_topics', hue=\"iterations\", y='UMass_coherence', data=df_perf[df_perf['implementation'] == 'Gensim'], pallete=\"Blues\", ax=ax1)\n",
    "    sns.pointplot(x='num_topics', hue=\"iterations\", y='UMass_coherence', data=df_perf[df_perf['implementation'] == 'Mallet'], pallete=\"Blues\", ax=ax1)\n",
    "    plt.suptitle('Num topics vs mean time', fontsize=20)\n",
    "    ax1.set_title('Gensim')\n",
    "    ax2.set_title('Mallet')\n",
    "else :\n",
    "    print(\"UMass_coherence not available in file\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Whether tf-idf transformation is appropriate for our LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if 'UMass_coherence' in df_perf.columns :\n",
    "    f, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 4))\n",
    "    sns.pointplot(x='num_topics', hue=\"tf-idf\", y='UMass_coherence', data=df_perf[df_perf['implementation'] == 'Gensim'], pallete=\"Blues\", ax=ax1)\n",
    "    sns.pointplot(x='num_topics', hue=\"tf-idf\", y='UMass_coherence', data=df_perf[df_perf['implementation'] == 'Mallet'], pallete=\"Blues\", ax=ax1)\n",
    "    plt.suptitle('Num topics vs mean time', fontsize=20)\n",
    "    ax1.set_title('Gensim')\n",
    "    ax2.set_title('Mallet')\n",
    "else :\n",
    "    print(\"UMass_coherence not available in file\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
